# Superjob Analytics

Целью данного проекта анализ IT вакансий, размещенных на [ресурсе Superjob](www.superjob.ru/vakansii/it-internet-svyaz-telekom/). Проект состоит из 4 этапов:

### 1. Регулярное скачивание данных
**Стек**: Python, Airflow </br>
Ежедневно запускается dag, который парсит актуальные вакансии и сохраняет данные локально в формате Parquet. </br>
Какая информация ищется:
- Название и url вакансии;
- Зарплата;
- Локация;
- Требуемый уровень образования;
- Требуемый опыт работы;
- Тип занятости;
- Детальное описание вакансии;


### 2. Загрузка данных в хранилище
**Стек:** Airflow, Hadoop </br>
После того, как новые данные появились локально, происходит их загрузка в хранилище с помощью автоматического запуска dag-а.

### 3. Расчеты метрик в хранилище
**Стек:** Airflow, Hadoop </br>
Рассчитываемые метрики:
- Динамика общего числа вакансий по неделям;
- Динамика общего числа вакансий по ключевым словам, например: ;
- Расчет статистик зарплаты по ключевым словам из описания вакансий, например: ;
- Расчет статистик зарплаты в разрезе уровня образования;
- Расчет статистик зарплаты в разрезе опыта работы;
- Расчет динамики числа вакансий в разрезе опыта работы;

### 4. Telegram бот для получения данных
**Стек:** Docker, Hadoop, Python </br>
Внутри бота реализован простой функционал для получения рассчитанных метрик из хранилища.
